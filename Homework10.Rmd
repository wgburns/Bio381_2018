---
title: "Homework10"
author: "Wilton Burns"
date: "March 29, 2018"
output: html_document
---

##Batch processing (continued)

#### 1. Go to the main course webpage, and follow the link to yesterday’s Batch Processing lecture. Scroll down near the end of that markdown file to find the code we were working on and the place we left off. The next line of code you should be entering is:
`fileNames <- list.files(path=fileFolder) `

#### 2. Finish your program by adding in the rest of the code. You can quickly cut and paste everything in, although you won’t learn much that way. A better and slower approach is to type in each line (as we do in class), get it to work, and see if you can understand what each line is doing. Lauren can help explain any of the lines of code that are not clear.
I kept NG's comments in and put in comments in my own words so that I could work through each step of the code. 

```{r, warning=FALSE}
# Basic code for batch processing 
# March 27 2018 
# WGB 


########################################################
# FUNCTION: FunctionName
# one line description 
# input: x
#       : fileFolder = 
#       : fileNA = c(min,max) number of rows in file 
# output:  set of random files 
FileBuilder <- function(fileN = 10, 
                        fileFolder = "RandomFiles/",
                        fileSize = c(15,100),
                        fileNA = 3){
  for (i in seq_len(fileN)) {
    fileLength <- sample(fileSize[1]:fileSize[2], size=1)
    varX <- runif(fileLength) # random x values 
    varY <- runif(fileLength) # random y values 
    dF <- data.frame(varX, varY) # bind to data frame 
    badVals <- rpois(n=1, lambda = fileNA) # number of NA 
    dF[sample(nrow(dF), size = badVals),1] <- NA 
    dF[sample(nrow(dF), size = badVals),2] <- NA 
    
# create a consecutive file name for this data frame 
# want a chr string that will become the name of that data file 
fileLabel <- paste(fileFolder,
                   "ranFile",
                   formatC(i, 
                           width = 3, 
                           format = "d",
                           flag = "0"),
                   ".csv", sep = "") 
# set up data file and incorporate time stamp and minimal metadata
write.table(cat("# simulated random data file", 
                "for batch processing", "\n",
                "# timestamp: ", as.character(Sys.time()), "\n",
                "# WGB", "\n",
                "# ------------------", "\n",
                "\n",
                file = fileLabel,
                row.names="",
                col.names="",
                sep=""))
 
# add the data frame now 
write.table(x=dF,
            file=fileLabel, 
            sep=",",
            row.names=FALSE, 
            append=TRUE)
  } # close the for loop
} # close the function 
#------------------------------------------------------


#############################################
# FUNCTION: regStats
# fit linear regression model, get stats
# input: 2 column data frame
# output: slope,p-value,r2
regStats <- function(d=NULL){
  if(is.null(d)){
    xVar <- runif(10)
    yVar <- runif(10)
    d <- data.frame(xVar,yVar)
  }
  . <- lm(data=d,d[,2]~d[,1]) # column y 
  . <- summary(.)
  statsList <- list(Slope=.$coefficients[2,1],
                    pVal=.$coefficients[2,4],
                    r2=.$r.squared)
  return(statsList)
} #end function regStats
#-------------------------------------------------------


# Start body of program 
library(TeachingDemos)
char2seed("Freezing March") # really not sure what this line does! Will have to ask Lauren...


# Global Variables 
fileFolder <- "RandomFiles/" # telling the program where to find the folder w the files
nFiles <- 100 # want 100 files bc that's what I set my function to 
fileOut <- "StatsSummary.csv" # naming the output file

# Create 100 random datasets
FileBuilder(fileN=nFiles)
fileNames <- list.files(path=fileFolder) # this is more simple to do in the code because we set up the global variables 

# Create data frame to hold file summary statistics
# here we are just making "blank dataset" with the correct number of NAs so that we can fill it in later with our batch processing loop 
ID <- seq_along(fileNames) 
fileName <- fileNames
slope <- rep(NA,nFiles)
pVal <- rep(NA,nFiles)
r2 <- rep(NA,nFiles)

# creating the data frame with all the columns we need and the right number of rows
statsOut <- data.frame(ID,fileName,slope,pVal,r2)

# batch process by looping through individual files
for (i in seq_along(fileNames)) {
  data <- read.table(file=paste(fileFolder,fileNames[i],sep=""),
                     sep=",",
                     header=TRUE) # read in next data file
  
  dClean <- data[complete.cases(data),] # get clean cases
  
  . <- regStats(dClean) # pull regression stats from clean file
  statsOut[i,3:5] <- unlist(.) # unlist, copy into last 3 columns
  
}

# set up output file and incorporate time stamp and minimal metadata
# so when I open up the StatsSummary csv I should see the metadata at the top, which I do :)
write.table(cat("# Summary stats for ",
                "batch processing of regression models","\n",
                "# timestamp: ",as.character(Sys.time()),"\n",
                "# NJG","\n",
                "# ------------------------", "\n",
                "\n",
                file=fileOut,
                row.names="",
                col.names="",
                sep=""))

# now add the data frame
write.table(x=statsOut,
            file=fileOut,
            row.names=FALSE,
            col.names=TRUE,
            sep=",",
            append=TRUE)


```

#### 3. When the script is complete, throw out the files in the RandomFiles folder and then run the script. It should generate 100 random data files in the folder. In the root of the project directory, you should find the file StatsSummary.csv. Open these files (they will open in Excel if you double click them) and make sure you understand what they contain, and how they are organized.
- I just threw out the files manually in the box in the lower right hand corner of R studio. 
- I ran the script after clearing out my environment/files and then found the 100 riles in the RandomFiles folder and then also found the csv file StatsSummary. The ID corresponds with the File name/number and then in each column there is the slope, pval, and r2 of the random dataset created with the regStats function where we use a linear regression model to analyze the random dataset. 
- This set of batch processing code first set up the file folder where the datasets were created and sent to, then we made a function to do linear regression models on each random dataset created, then we created an output dataframe then csv for the important summary stats to go into so that they're saved. 

####4. Try “breaking” the program by decreasing the range of possible row numbers in each random file, and/or increasing the number of NA values that are randomly created (what will you have to change in the code to achieve this?). Change parameters gradually until you create a data file that cannot be fit with lm because there aren’t enough data. What happens? Does the program fail entirely or create some of the output? Are there any error messages? Be sure to delete the files within the RandomFiles folder (but do not delete the folder itself!), and also delete the StatsSummary.csv file before you run each of your “experiments”.
- First, I copy and pasted the code below this question because I wanted to make sure that I preserved the code above before messing with it! 
- Next, I tried decreasing the range of possible row numbers in each random file by changing the number of varX and varY in the FileBuilder function to be 10 (was previously runif(fileLength). 
- What happens? I created that function and just like I told it, the number of files in the RandomFiles folder is just 10. Not sure what that means for when I run the rest of the script, we'll see. Okay so nothing happened I think because 
**a) Does the program fail entirely or create some of the output?**

**b) Are there any error messages?**


```{r}
# Basic code for batch processing (TRYING TO BREAK THE CODE)
# March 29 2018 
# Homework 10
# WGB 


########################################################
# FUNCTION: FunctionName
# one line description 
# input: x
#       : fileFolder = 
#       : fileNA = c(min,max) number of rows in file 
# output:  set of random files 
#------------------------------------------------------
FileBuilder <- function(fileN = 10, 
                        fileFolder = "RandomFiles/",
                        fileSize = c(15,100),
                        fileNA = 3){
  for (i in seq_len(fileN)) {
    fileLength <- sample(fileSize[1]:fileSize[2], size=1)
    varX <- runif(15) # random x values 
    varY <- runif(15) # random y values 
    dF <- data.frame(varX, varY) # bind to data frame 
    badVals <- rpois(n=1, lambda = fileNA) # number of NA 
    dF[sample(nrow(dF), size = badVals),1] <- NA 
    dF[sample(nrow(dF), size = badVals),2] <- NA 
    
# create a consecutive file name for this data frame 
# want a chr string that will become the name of that data file 
fileLabel <- paste(fileFolder,
                   "ranFile",
                   formatC(i, 
                           width = 3, 
                           format = "d",
                           flag = "0"),
                   ".csv", sep = "") 
# set up data file and incorporate time stamp and minimal metadata
write.table(cat("# simulated random data file", 
                "for batch processing", "\n",
                "# timestamp: ", as.character(Sys.time()), "\n",
                "# WGB", "\n",
                "# ------------------", "\n",
                "\n",
                file = fileLabel,
                row.names="",
                col.names="",
                sep=""))
 
# add the data frame now 
write.table(x=dF,
            file=fileLabel, 
            sep=",",
            row.names=FALSE, 
            append=TRUE)
  } # close the for loop
} # close the function 



#######################################################
# FUNCTION: regStats
# fit linear model, get regression stats
# input: 2-column data frame
# output: slope, p-value and r2
#------------------------------------------------------
#############################################
# FUNCTION: regStats
# fit linear regression model, get stats
# input: 2 column data frame
# output: slope,p-value,r2
#------------------------
regStats <- function(d=NULL){
  if(is.null(d)){
    xVar <- runif(10)
    yVar <- runif(10)
    d <- data.frame(xVar,yVar)
  }
  . <- lm(data=d,d[,2]~d[,1]) # column y 
  . <- summary(.)
  statsList <- list(Slope=.$coefficients[2,1],
                    pVal=.$coefficients[2,4],
                    r2=.$r.squared)
  return(statsList)
} #end function regStats

#-------------------------------------------------------
# Start body of program 
library(TeachingDemos)
char2seed("Freezing March") # really not sure what this line does! Will have to ask Lauren...

#------------------------------------------------

# Global Variables 
fileFolder <- "RandomFiles/" # telling the program where to find the folder w the files
nFiles <- 100 # want 100 files bc that's what I set my function to 
fileOut <- "StatsSummary.csv" # naming the output file

# Create 100 random datasets
FileBuilder(fileN=nFiles)
fileNames <- list.files(path=fileFolder) # this is more simple to do in the code because we set up the global variables 

# Create data frame to hold file summary statistics
# here we are just making "blank dataset" with the correct number of NAs so that we can fill it in later with our batch processing loop 
ID <- seq_along(fileNames) 
fileName <- fileNames
slope <- rep(NA,nFiles)
pVal <- rep(NA,nFiles)
r2 <- rep(NA,nFiles)

# creating the data frame with all the columns we need and the right number of rows
statsOut <- data.frame(ID,fileName,slope,pVal,r2)

# batch process by looping through individual files
for (i in seq_along(fileNames)) {
  data <- read.table(file=paste(fileFolder,fileNames[i],sep=""),
                     sep=",",
                     header=TRUE) # read in next data file
  
  dClean <- data[complete.cases(data),] # get clean cases
  
  . <- regStats(dClean) # pull regression stats from clean file
  statsOut[i,3:5] <- unlist(.) # unlist, copy into last 3 columns
  
}

# set up output file and incorporate time stamp and minimal metadata
# so when I open up the StatsSummary csv I should see the metadata at the top, which I do :)
write.table(cat("# Summary stats for ",
                "batch processing of regression models","\n",
                "# timestamp: ",as.character(Sys.time()),"\n",
                "# NJG","\n",
                "# ------------------------", "\n",
                "\n",
                file=fileOut,
                row.names="",
                col.names="",
                sep=""))

# now add the data frame
write.table(x=statsOut,
            file=fileOut,
            row.names=FALSE,
            col.names=TRUE,
            sep=",",
            append=TRUE)


```